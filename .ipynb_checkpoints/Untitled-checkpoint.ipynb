{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprting necessary packages\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "import tkinter\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.python.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.layers import MaxPooling2D\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making model using squential and adding layers\n",
    "emotion_model = Sequential()\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "emotion_model.save_weights('model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "emotion_dict = {0: \"   Angry   \",1: \"    Disgusted   \" ,2:\"   Frearful   \",3:\"   Happy   \",4:\"   Neutral   \",5:\"   Sad   \",6 : \"   Surprised   \" }\n",
    "\n",
    "emoji_dist = {0:\"./emojis/angry.png\",1:\"./emojis/disgusted.png\",2:\"./emojis/fearful.png\",3:\"./emojis/happy.png\",4:\"./emojis/neutral.png\",5:\"./emojis/sad.png\",6:\"./emojis/surpriced.png\",}\n",
    "\n",
    "global last_frame1\n",
    "\n",
    "last_frame1 = np.zeros((480 , 640, 3), dtype=np.uint8)\n",
    "global cap1\n",
    "show_text=[0]\n",
    "global frame_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video processing function\n",
    "def show_subject():      \n",
    "    cap1 = cv2.VideoCapture(0)    #to open our video/webcam       \n",
    "    ret, frame = cap1.read()                      \n",
    "    if not cap1.isOpened():                             \n",
    "        print(\"cant open the camera1\")\n",
    "    global frame_number\n",
    "    length = int(cap1.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_number += 1 \n",
    "    if frame_number >= length:\n",
    "        exit()\n",
    "    cap1.set(1,frame_number)\n",
    "    flag1, frame1 = cap1.read()     #flag1 tells us if we reading soemthing or not  and frame1 is an array btowh would be returned by read() function \n",
    "    frame1 = cv2.resize (frame1,(600,500)) #resizing the camera\n",
    "    bounding_box = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "    gray_frame = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor =1.3 ,minNeighbors = 5)\n",
    "    for(x,y,w,h) in num_faces:\n",
    "        cv2.rectangle(frame1,(x,y-50),(x+w , y+h+10),(255,0,0) ,2)\n",
    "        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame,(48,48)), -1 ), 0)\n",
    "        prediction = emotion_model.predict(cropped_img)\n",
    "        maxindex= int(np.argmax(prediction))\n",
    "        cv2.putText(frame1, emotion_dict[maxindex], (x+20 , y-60), cv2.FONT_HERSHEY_SIMPLEX ,1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        show_text[0] = maxindex\n",
    "    if flag1 is None:\n",
    "        print (\"Major error!\")\n",
    "    elif flag1:\n",
    "        global last_frame1\n",
    "        last_frame1= frame1.copy()\n",
    "        pic = cv2.cvtColor(last_frame1 ,cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(pic)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        lmain.imgtk = imgtk\n",
    "        lmain.configure(image=imgtk)\n",
    "        root.update()\n",
    "        lmain.after(10, show_subject)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_avatar():   #avatar/ emoji placement\n",
    "    frame2=cv2.imread(emoji_dist[show_text[0]])\n",
    "    pic2=cv2.cvtColor(frame2,cv2.COLOR_BGR2RGB)\n",
    "    img2=Image.fromarray(frame2)\n",
    "    imgtk2=ImageTk.PhotoImage(image=img2)\n",
    "    lmain2.imgtk2=imgtk2\n",
    "    lmain3.configure(text=emotion_dict[show_text[0]],font=('arial',45,'bold'))\n",
    "    \n",
    "    lmain2.configure(image=imgtk2)\n",
    "    root.update()\n",
    "    lmain2.after(10, show_avatar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\tkinter\\__init__.py\", line 804, in callit\n",
      "    func(*args)\n",
      "  File \"<ipython-input-4-9efb682e2006>\", line 33, in show_subject\n",
      "    imgtk = ImageTk.PhotoImage(image=img)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\PIL\\ImageTk.py\", line 112, in __init__\n",
      "    self.__photo = tkinter.PhotoImage(**kw)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\tkinter\\__init__.py\", line 4061, in __init__\n",
      "    Image.__init__(self, 'photo', name, cnf, master, **kw)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\tkinter\\__init__.py\", line 3994, in __init__\n",
      "    raise RuntimeError('Too early to create image')\n",
      "RuntimeError: Too early to create image\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    frame_number = 0          #global variable\n",
    "    root=tkinter.Tk()\n",
    "    lmain = tkinter.Label(master=root,padx=50,bd=10)    #labels which contents images/video\n",
    "    lmain2 = tkinter.Label(master=root,bd=10)           #labels which contents images/video\n",
    "    lmain3 = tkinter.Label(master=root,bd=10, fg=\"#CDCDCD\", bg='grey')\n",
    "    lmain.pack(side=LEFT)\n",
    "    lmain.place(x=50,y=250)\n",
    "    lmain3.pack()\n",
    "    lmain3.place(x=960,y=250)\n",
    "    lmain2.pack(side=RIGHT)\n",
    "    lmain2.place(x=900,y=350)\n",
    "\n",
    "    root.title(\"Photo of Emoji\")   #specified title\n",
    "    root.geometry(\"1400x900+100+10\")\n",
    "    root['bg']='black'    #gui background\n",
    "    exitButton = Button(root, text='Quit',fg = \"red\", command=root.destroy, font= ('arial',25,'bold')).pack (side= BOTTOM)\n",
    "    threading.Thread(target=show_subject).start()   #subject function  #in new threads\n",
    "    threading.Thread(target=show_avatar).start()    #avatar function \n",
    "    root.mainloop()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
